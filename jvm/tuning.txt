1:Profiling Tools
------------------------------------------------------------------------------------------------------
1.1| free=>jvisualvm: 
    present in jdk along with java, javac
    much better than jconsole
    automatically monitors process that uses its parent jdk
    gives cpu, heap, ram monitoring
    can wire up with remote hosts and uses jmx/jstats
    can analyse thread dumps

1.2| commercial=> Yourkit, Jprofile

------------------------------------------------------------------------------------------------------
2: DIY
-------
2.1 CPU Profiling:
------------------*
System.currentMilliSec() => for rarely called long running methods
ConcurrentHashMap => for frequently called short running methods. Use the data to get averages.
Sampling - Analyse threaddumps to get hotspots (bad performing code)
    a| kill -3 pid > dump.txt 
    b| jstack pid > dump.txt
    c| Thread.getAllStacktraces() -for programmatically getting all threads

2.2: Memory Profiling:
----------------------*
a|  'jps' => find pids of java processes

b|  'jmap -histo <pid>' => gives number of instances and memory consumed per class
    'jmap -histo:live <pid>' => does a garbage collection before counting instances, 10 sec pause, cannot be used in prod
    'jmap -dump:<options> <pid>' => gives thread dumps

c|  JVM options
    '-XX:+PrintClassHistogram' => on 'kill -3' will call 'jmap -histo'
    '-XX:+HeapDumpOnOutOfMemoryError' => produces dump in hprof format
    CPU and thread profiling wont help in analysing big memory allocation issues.Only slow GC reflect the issue.    
    JVM flags: 
    3.1| 'verbose:gc, -XX:+PrintGC, +-XX:+PrintGCDetails' => logs time spent on GC
    3.2| '-Xaprof'=> pints memory allocation by class on process exit

d|  Use byte code manipulation with javassist to do more tracking
    runtime byte code manipulation can be done with javaagent

------------------------------------------------------------------------------------------------------
3: Garbage Collection |Mechanical Sympathy
-------------------------------------------*
Generation GC (eden.survivor, tenured) algorithms may not be good when you create a lot of long-lived objs.

3.1| Throughput => The amount of work done by an application as a ratio of time spent in GC. 
   Target throughput with 'XX:GCTimeRatio=99';99 is the default equating to 1% GC time.

3.2| Latency => The time taken by systems in responding to events which is impacted by pauses introduced by garbage collection. 
   Target latency for GC pauses with 'XX:MaximumGCPauseMillis=<n>'.

3.3| Memory => The amount of memory our systems use to store state, which is often copied and moved around when being managed. 
   The set of active objects retained by the application at any point in time is known as the Live Set. 
   Maximum heap size '–Xmx<n>' is a tuning parameter for setting the heap size available to an application.

3.4| Stop the world events => All threads must come to a safe point before GC can proceed.
   '-XX:PrintGCApplicationStoppedTime' will show this.

4: Heap Organisation:
----------------------*
a| eden => the region of fresh objects
b| survivor => regions where objs that survived one eden collection.
c| tenured => long lived objs
d| perm => non-heap region for class, static strings, java 8 dumped it

5: TLAB:
---------*
Each thread is allocated a Thread Local Allocation Buffer in eden space.
They create objs by bumping up a pointer in this space
No contentions between threads, much faster than C malloc
But when large objs are created, the TLAB can be a limiter, so the new big obj is in the tenured generation.'-XX:PretenureSizeThreshold=<n>'

-----------------------------------------------------------------------------------------------------------------------------------------------
6:COLLECTION:

6.1 Minor Collection:
---------------------*
Movement of objs from eden to survivor to tenured
Search through live objs using object graphs and also any back references from older generation to new generation(card table)
survivor space has 2 spaces (from-space, to-space)
    to-space => target region to store newly moved objs during collection
    from-space => stores objs from previous collection, also undergoes collection during minor stage.
cost of collection is tied more to number of instances than memory, but doubling eden space can help in reducing minor collection frequency.
– XX:MaxTenuringThreshold=<n> => jvm flag to control ageing of objs

6.2 Major Collection:(full GC)
---------------------*
Removal and compaction of objs from tenured to make space for promotion of new ones from survivor spaces
Major collector algos use a threshold to start or a full GC will be initiated where all objs from survivor spaces are moved.
Promotion failure is costly, avoid -XX:PromotedPadding=<n>
When the Heap needs to grow a FullGC is triggered. These heap-resizing FullGCs can be avoided by setting –Xms and –Xmx to the same value.
-----------------------------------------------------------------------------------------------------------------------------------------------
7:COLLECTORS
-------------*

7.1|Serial Collector:'-XX:+UseSerialGC' 
    1 thread for minor and major collections, good for single processor systems, small memory footprint

7.2|Parallel Collector:'-XX:+UseParallelGC'
    multiple threads for minor collections, 1 thread for major collections

7.3|Parallel Old Collector: '-XX:+UseParallelOldGC'
    multiple threads for minor collections, multiple threads for major collections, default in all jvms since 7u4
    best for multi-processor systems
    dependent on number of objs than size
    if too much pause(1-5 sec/1GB of data), use a collector that can run concurrently with application.

7.4|Concurrent Mark and Sweep CMS Collector:'-XX:+UseConcMarkSweepGC'
    minor collections are slow
    Works concurrently on tenured spaces, takes up CPU along with app, 
    Does not compact, make free lists out of freed-up memory, can result in voids, making them unfillable for large objects from eden/survivor. 
    This fragmentation can trigger fullGC.
    Requires extra memory for tracking datastructures
    CMS can suffer “concurrent mode failures”, which can be seen in the logs, when it fails to collect at a sufficient rate to keep up with promotion. 
    
    Process:
    --------- 
    initial mark=> find GC roots
    concurrent mark=> mark all objs reachable from roots
    concurrent preclean => check for updated references from previous phase
    re-mark => mark again
    concurrent sweep => reclaim memory into free lists by deleting dead objects
    concurrent reset => reset datastructures.

7.5|Garbage First Collector G1:'-XX:+UseG1GC' 
    From Oracle
    Breaks the heap into small regions with mixed owners ede, survivor, tenured and humungous
    Partially concurrent running every 200ms (G1 is target driven on latency '–XX:MaxGCPauseMillis=<n>')
    Remembers references between objects in different regions via 'Remembered Sets'
    G1 takes the approach of concurrently marking regions to track references between regions, and to focus collection on the regions with the most free space
    Objects larger than 50% of a region are allocated in humongous regions
    Popular objs and region can cause issues.
    G1 is a goodfor larger heaps that have a tendency to become fragmented when an application can tolerate pauses in the 0.5-1.0 second range for incremental compactions. 
    Works on avoiding fullGC by preventing fragmentation.

  
7.6|Alternative collectors 
    Oracle JRockit Real Time, IBM Websphere Real Time, and Azul Zing. The JRockit & Websphere collectors have latency advantages in most cases over CMS and G1,
    but often see throughput limitations and still suffer significant stop-the-world events. 

7.7|C4 algorithm:
    Upgrade of the Azul Systems Pauseless GC algorithm, currently implemented only for the Zing JVM
    C4 algorithm does compaction concurrently with running application threads
    C4 wants as large a heap as possible to guarantee that a free page is always available for allocating threads
    So instead of 16JVMs with 2GB space, you would move to 2JVMs with 64GB heap.
    Consists of 3 phases

    7.7.1|Marking:
    ---------------
    'Dirty objects and Card tables'
    Objects that need to be revisited by the garbage collector for reasons like re-referencing are often called dirty objects. 
    References to dirty objects, or dirty areas of the heap, are usually managed in a separate data structure, known as a 'card table'

    C4 does NOT use Card table but relies on a self-healing 'load value barrier (LVB)', which enables application threads to immediately see if a reference is already marked. 
    If the reference is not marked, the application thread will add it to the GC queue. 
    Once the reference is in the queue it cant be re-marked. The application thread is free to continue on with its work
    So endless remarking loops like other algos are avoided.


    7.7.2|Relocation:
    ------------------*
    Collaborative and concurrent
    If a GC thread tries to move a object that is not used by any application thread, its simple.
    In the other case, the application thread escalates the relocation to happen faster.
    Larger objects are moved via 'shattered object moves'

    7.7.3|Remapping
    handles updating references that are still pointing to a page where live objects have been moved out. 
    Concurrent and collaborative.

7.8|IBM JVM Balanced Garbage Collection Policy:'-Xgcpolicy:balanced'
    Like G1 breaks heap into equal small regions
    Works only with 64bit, NUMA and > 4GB heaps.
    Heuristics are applied to choose which regions to garbage-collect for the best return on effort. 


-------------------------------------------------------------------------------------------------------------------------------------------------------------------
8 MONITORING
-------------*
-verbose:gc
-Xloggc:
-XX:+PrintGCDetails
-XX:+PrintGCDateStamps
-XX:+PrintTenuringDistribution
-XX:+PrintGCApplicationConcurrentTime 
-XX:+PrintGCApplicationStoppedTime

-------------------------------------------------------------------------------------------------------------------------------------------------------------------
9: JVM Performance Tuning| Charlie Hunt InfoQ
---------------------------------------------*
GC:
---*
1|  frequency of minor collections is dependent upon eden space size and obj allocation rate. minor GC pause time is dependent upon number of live objects.
2|  frequency of major collections is dependent upon minor collections frequency and survivor space size.
3|  objects rentention is bad, leads to longer GC.
4|  throughput, latency, footprint - u can get only 2 out of 3, achieving all 3 is tough
5|  size of java heap does not matter, only number of live objects
6|  gc loves small immutable objects for quick operations than mutable long living objects. But frequent allocations lead to more minor collections.
7|  its a delicate balance heap-resizing
8|  ideal => more minor gc (generally fast, UseParallelOldGC) and less major GC, 

9|  parallel GC: fast minor collections, if you can avoid fullGC, its nice
10| CMS GC:slow minor collections due to promotion to fragmented(free lists) tenured space, avoids fullGC by concurrent collections of older generations
11| G1 GC:slow minor collections due to Remembered sets, avoids fullGC by concurrent collections and no fragmentation issues.
    Works with user-set heap size and pause-time to achieve the best possible. No separate setting of specific generation sizes.

12| large objects are bad for cpu, initialisation and CMS GC.
13| array backed collections are bad, set to an fixed size if you can. This causes fragmentation.
14| object pooling is more live objects, so longer minor collections.
15| finalizers are super bad, requires 2 slower GC cycles. use Reference Objects
16| soft references are bad.
17| inner class hold references to outer class, so increased obj rentention.

18| fullGC => dependent upon tenured space and collector
    when CMS (fragmentation), G1 loses the concurrent race, fullGC is initiated    
    CMS has the biggest pause

JIT
----*
Does not have full program knowledge, knows only the classes loaded.
Makes optimisation based on program execution
Keeps adapting based on changes
Inlining is good and Virtualisation is bad as it blocks inlining.
Dont start writing JIT compliant code, just identify issues and tackle.

Code Cache:
-----------*
48M pre Java 8- 96Mb in Java 8; -XXReservedCodeCacheSize=<n>
is depleted in case of large systems, application slowing down is the only sympton

Use monitoring like jconsole or jvisualvm.
-XX:+PrintCompilation might help by showing up lines like 'make non-entrant, made zombie'
-XX:+UseCodeCacheFlushing after Java 6 will help, turned on in J7, might be intrusive to JIT

Tools:
-------*
GCHisto, GCViewer
-XX:+PrintTimeStamps,-XX:PrintGCDateStamps, -XX:PrintGCDetails will help (safe to use in PROD)
VisualGC plugin in jvisualvm
-XX:+PrintOptoAssembly,-XX:+LogCompilation  to view JIT code
Oracle Solaris Studio Analyser
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
10: JVM Tuning:JavaWorld 5 part series
---------------------------------------*
10.1|Compilers 
---------------*
two types:
    static: javac - compile only once 
    dynamic: JIT - compiles adaptively during runtime, does code optimisation. more cpu, threads, memory.
two phases:
    .java -> .class file (bytecode - javac)
    .class -> machine code (jvm compiler, jit)
Byte code to machine code
--------------------------
'Interpretation'=>
An interpreter simply looks up the hardware instructions for every bytecode instruction and sends it off to be executed by the CPU
No optimisation, looks up everytime line by line.
'Compilation'=>
Looks up the entire/partial runtime context and produces optimal machine code.
machine are stored in 'code cache' for frequently accessed code 
uses 'performance counters' to reduce repeated bytecode which translates to a better set of machine code.
    
    '-client'=> C1 used in case of limited resources, 
                non-intrusive optimisations
                less application startup time
    '-server'=> C2 long running applications, 
                advanced optimisations, 
                takes some warmup time to identify hostspots, 
                more CPU cycles and threads,
                bigger code cache
    'tiered'=>  introduced by Azul in Zing, then adopted by Oracle
                initial compilation is C1, which sets up the performance counters for the next phase C2            

'optimisations'=>
    remove dead code
    inline methods
    group loops: combining neighbouring independent loop codes.
    tiling loops: grouping code and data blocks around cpu caches.
    inversion loops: change 'while' to 'do-while'
    unrolling loops: Reduces the number of times the loop condition has to be evaluated and also the number of jumps

10.2|Java Scalability*
----------------------
Java application 'memory wall' - 1-4GB heap
too little heap=> out of memory, too much heap=>fragmentation and big pauses.
A worst-case pause time in a production environment is around '1sec/1GB' of live data in the heap.
So either multiple JVMs in a cluster-ops nightmare OR big heap with postponed fullGC during non-peak hours
Most cases people are running with peak load heap sizes to avoid failure, but its wastage.
Setting eden size matter and should be done in prod-like environment

-------------------------------------------------------------------------------------------------------------------------------------------------------------------
11: JVM Flags: Java revisited
------------------------------*

'-X' => non-standard (thy are not guaranteed to be supported on all JVM implementations), and are subject to change without notice in subsequent jdk releases.
'-XX' => not stable and are not recommended for casual use. These options are subject to change without notice also.
'Boolean' JVM options can be turned on with '-XX:+' and can be turned off with '-XX:-'
'Numeric' JVM Options can be set with '-XX:='. Numbers can include 'm'|'M' for megabytes, 'k'|'K' for kilobytes, and 'g'|'G' for gigabytes
    'java -Xms512m -Xmx512m BigApp'
    'java -Xss120m'
'String' JVM options can be set by using '-XX:=', and usually used to specify a file, a path, or a list of commands.
ManagementFactory.getRuntimeMXBean().getInputArguments() to give running JVM options

space :
------*
'-Xms384m -Xmx384m -XX:NewSize=128m -XX:MaxNewSize=128m' => 1/3 of heap is for eden
'-XX:NewRatio=2 '=>  Ratio of new to old generation sizes.
'-XX:SurvivorRatio=8' => Ration of eden to survivor spaces
'-XX:PermSize=64m -XX:MaxPermSize=128m'=> Size of the Permanent Generation.

GC:
---*
'-verbose:gc'=> logs garbage collector runs and how long they are taking. 
'-XX:-PrintGCTimeStamps'=>  print timestamps at garbage collection.
'-XX:-UseSerialGC'=>        Use serial garbage collection.
'-XX:+UseParallelGC'=>      Use parallel garbage collection for scavenges
'-XX:-UseConcMarkSweepGC'=> Use concurrent mark-sweep collection for the old generation

debug/log:
----------*
'-Xdebug -Xnoagent -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000' => for remote debugging.
'-Xprof-Xrunhprof'=> for profiling
'-Xbootclasspath'=> to load classes without verification
'-XX:+TraceClassLoading -XX:+TraceClassUnloading' => print class loading details
'-XX:+PrintCompilation' => prints JIT compiled methods
'-XX:HeapDumpPath=./java_pid.hprof' =>  Path to directory or file name for heap dump.
'-XX:-PrintConcurrentLocks' =>  Print java.util.concurrent locks in Ctrl-Break thread dump.
'-XX:-PrintCommandLineFlags' => Print flags that appeared on the command line.
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
12: FAQs on ORacle website:
-----------------------------*
The maximum theoretical heap limit for the 32-bit JVM is 4G.
A 64-bit capable J2SE is an implementation of the Java SDK (and the JRE along with it) that runs in the 64-bit environment of a 64-bit OS on a 64-bit processor. 
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
13:IBM Developerworks:Brian Goetz - 
---------------------------------*
some features will be available in IBM JVM only

memory alloc/deallocs were costly before 1.2
Sun estimates allocation costs at approximately '10 machine instructions' which is very cheap
sometimes a obj can be just allocated on stack instead of heap if its too short lived.
'finalizers' are bad, they must be executed only by GC thereby requires 2 cycles to clean these objs (1 cycle to identify, 1 cycle to execute finalise)
'object pooling' is bad 
    its ok only for objects that are costly to create and numbers are small
    tough to maintain a synchronised access system for all threads using it
    deallocation is done manually, which in most cases incorrect.
'explicit nulling' is bad
    useless in most cases, can be dangerous in some cases
    ok for situations like a stack backed by an array. When the element is dequeued and the head pointer is updated, just nullify the reference.
'explicit gc' is bad
    System.gc triggers fullGC which is bad
    JVM knows better than you when to collect
    '-XX:+DisableExplicitGC' will eliminate hidden calls if any in codebase.
'immutability' is good
    Older generation mutable objects which are updated reqularly will hold links to objs in new generation.
    The use of mutable references for long-lived container objects increases the work done to track old-to-young references at collection time.
    young-to-old references driven by immuatability are gentle for GC













    










